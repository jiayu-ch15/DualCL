{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'sim' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n sim ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tensordict import TensorDict\n",
    "from tensordict.nn import TensorDictModule, TensorDictSequential\n",
    "from torchrl.envs.transforms import CatTensors\n",
    "from omni_drones.learning.dreamer import models, networks\n",
    "from omni_drones.learning.modules.networks import MLP\n",
    "from omni_drones.learning.modules.distributions import (\n",
    "    MultiOneHotCategorical, IndependentNormalModule\n",
    ")\n",
    "from omni_drones.learning.common import make_encoder\n",
    "\n",
    "from torchrl.data import TensorSpec\n",
    "from typing import Sequence\n",
    "\n",
    "class ObsEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_cfg,\n",
    "        observation_spec: TensorSpec,\n",
    "        embed_dim: int,\n",
    "        deter_dim: int,\n",
    "        stat_shape: torch.Size,\n",
    "        units: Sequence[int],\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = make_encoder(encoder_cfg, observation_spec)\n",
    "        self.obs_out_layers = MLP(\n",
    "            [deter_dim + embed_dim] + units, \n",
    "            nn.LayerNorm\n",
    "        )\n",
    "        self.stat_shape = torch.Size(stat_shape)\n",
    "        self.stat_layer = nn.Linear(units[-1], self.stat_shape.numel())\n",
    "\n",
    "    def forward(self, obs, deter):\n",
    "        embed = self.encoder(obs)\n",
    "        x = torch.cat([deter, embed], dim=-1)\n",
    "        x = self.obs_out_layers(x)\n",
    "        stat = self.stat_layer(x).unflatten(-1, self.stat_shape)\n",
    "        return stat\n",
    "\n",
    "\n",
    "class ObsDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_spec: TensorSpec,\n",
    "        latent_dim: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.decoder = MLP(\n",
    "            [latent_dim] + [observation_spec.shape[-1]],\n",
    "            nn.LayerNorm\n",
    "        )\n",
    "    \n",
    "    def forward(self, latent):\n",
    "        x = self.decoder(latent)\n",
    "        return x \n",
    "\n",
    "\n",
    "class SampleFromDist(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dist_cls = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.dist_cls = dist_cls\n",
    "    \n",
    "    def forward(self, *args):\n",
    "        if self.dist_cls is not None:\n",
    "            dist = self.dist_cls(*args)\n",
    "        elif len(args) == 0:\n",
    "            dist = args[0]\n",
    "        else:\n",
    "            raise ValueError\n",
    "        samples = dist.rsample()\n",
    "        log_probs = dist.log_prob(samples)\n",
    "        entropy = dist.entropy()\n",
    "        return samples, log_probs, entropy\n",
    "\n",
    "\n",
    "def make_dreamer(\n",
    "    config,\n",
    "    observation_spec: TensorSpec,\n",
    "    action_spec: TensorSpec\n",
    "):\n",
    "    deter_dim: int\n",
    "    stoch_dim: int\n",
    "    discrete_dim: int\n",
    "    action_dim = action_spec.shape[-1]\n",
    "\n",
    "    obs_encoder = ObsEncoder(\n",
    "        config.encoder,\n",
    "        observation_spec,\n",
    "        embed_dim=config.obs_embed_dim,\n",
    "        deter_dim=deter_dim,\n",
    "        stat_shape=(stoch_dim, discrete_dim),\n",
    "        units=config.porj_units,\n",
    "    )\n",
    "    sequence_model = MLP(\n",
    "        [stoch_dim * discrete_dim + action_dim] + config.sequence_model.units, \n",
    "        nn.LayerNorm\n",
    "    )\n",
    "    dynamics_predictor = MLP(\n",
    "        [deter_dim] + config.dynamics_pred.units, \n",
    "        nn.LayerNorm\n",
    "    )\n",
    "\n",
    "    feat_size = stoch_dim * discrete_dim + deter_dim\n",
    "    task_actor = nn.Sequential(\n",
    "        MLP(\n",
    "            [feat_size] + config.actor.units, \n",
    "            nn.LayerNorm\n",
    "        ),\n",
    "        IndependentNormalModule(config.actor.units, action_dim),\n",
    "        SampleFromDist()\n",
    "    )\n",
    "\n",
    "    if config.value_head == \"twohot_symlog\":\n",
    "        value = MLP(\n",
    "            [feat_size] + config.value_pred.units + [255],\n",
    "            normalization=nn.LayerNorm\n",
    "        )\n",
    "    else:\n",
    "        value = MLP(\n",
    "            [feat_size] + config.value_pred.units + [1],\n",
    "            normalization=nn.LayerNorm\n",
    "        )\n",
    "\n",
    "    obs_decoder = ObsDecoder(\n",
    "\n",
    "    )\n",
    "\n",
    "    if config.reward_head == \"twohot_symlog\":\n",
    "        reward_predictor = MLP(\n",
    "            [feat_size] + config.reward_pred.units + [255],\n",
    "            normalization=nn.LayerNorm\n",
    "        )\n",
    "    else:\n",
    "        reward_predictor = MLP(\n",
    "            [feat_size] + config.reward_pred.units + [1],\n",
    "            normalization=nn.LayerNorm\n",
    "        )\n",
    "    \n",
    "    discount_predictor = reward_predictor = MLP(\n",
    "        [feat_size] + config.discont_pred.units + [1],\n",
    "        normalization=nn.LayerNorm\n",
    "    )\n",
    "\n",
    "    policy_modules = TensorDictSequential(\n",
    "        TensorDictModule(obs_encoder, [\"obs\", \"deter\"], [\"post_logit\"]),\n",
    "        TensorDictModule(\n",
    "            SampleFromDist(MultiOneHotCategorical), \n",
    "            [\"post_logit\"], [\"post_stoch\", \"_\", \"_\"]\n",
    "        ),\n",
    "        CatTensors([\"deter\", \"post_stoch\"], [\"latent\"], del_keys=False),\n",
    "        TensorDictModule(task_actor, [\"latent\"], [\"action\", \"log_prob\", \"entropy\"]),\n",
    "        TensorDictModule(value, [\"latnet\"], [\"state_value\"]),\n",
    "        TensorDictModule(sequence_model, [\"deter\", \"action\"], [(\"next\", \"deter\")]),\n",
    "    )\n",
    "\n",
    "    train_modules = TensorDictSequential(\n",
    "        TensorDictModule(dynamics_predictor, [\"deter\"], [\"prior_logit\"]),\n",
    "        TensorDictModule(\n",
    "            SampleFromDist(MultiOneHotCategorical), \n",
    "            [\"prior_logit\"], [\"prior_stoch\", \"_\", \"_\"]\n",
    "        ),\n",
    "        TensorDictModule(obs_decoder, [\"latnet\"], [\"obs_pred\"]),\n",
    "        TensorDictModule(reward_predictor, [\"latnet\"], [\"reward_pred\"]),\n",
    "        TensorDictModule(discount_predictor, [\"latnet\"], [\"discount_pred\"]),\n",
    "    )\n",
    "    \n",
    "    world_model = nn.ModuleDict({\n",
    "        \"obs_encoder\": obs_encoder,\n",
    "        \"dynamics_predictor\": dynamics_predictor,\n",
    "        \"sequence_model\": sequence_model,\n",
    "        \"reward_predictor\": reward_predictor,\n",
    "        \"discount_predictor\": discount_predictor,\n",
    "        \"obs_decoder\": obs_decoder\n",
    "    })\n",
    "\n",
    "    actor_ctiric = nn.ModuleDict({\n",
    "        \"actor\": task_actor,\n",
    "        \"critic\": value\n",
    "    })\n",
    "\n",
    "    return policy_modules, train_modules, world_model, actor_ctiric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as D\n",
    "\n",
    "loc = torch.zeros(32, 4, 16)\n",
    "scale = torch.ones_like(loc)\n",
    "d = D.Independent(D.Normal(loc, scale), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
